{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553f8dc4",
   "metadata": {},
   "source": [
    "# Tutorial material property identification using modelitool "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85508d",
   "metadata": {},
   "source": [
    "The aim of this tutorial is to provide a complete workflow from measured data treatment to material physical properties identification using **Modelitool** and **OpenModelica**.\n",
    "\n",
    "### _The use case is an example and the validity of the physical model or of the scientific approach is not discussed here_\n",
    "\n",
    "## Use case presentation\n",
    "\n",
    "The objective of the study is to identify the thermal conductivity of the insulation material \"ETICS\"\n",
    "using an experimental setup.\n",
    "\n",
    "A \"real scale\" benchmark is used. The Nobatek **BEF** (Banc d'Essais Façade)\n",
    " provides experimental cells to test building façade solutions. The heat exchanges\n",
    " in a cell are limited on 5 of its faces. The 6th face is dedicated to the tested solution.\n",
    "  Internal temperature and hydrometry conditions can be controlled or monitored.\n",
    "External conditions are measured (temperatures and solar radiation).\n",
    "\n",
    "The experimental setup is presented in the following pictures:\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"./etics_pict.png\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "<td> <img src=\"./etics_sch.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "- Figure 1 is a picture of the benchmark \n",
    "- Figure 2 represent the wall layers from the inside (right) to the outside (left)\n",
    "\n",
    "The stars represent the sensors positions. For each position 2 sensors are used providing two measures.\n",
    "\n",
    "- Measure campaign spans from the 07/06/2017 to the 20/06/2017\n",
    "- Acquisition timestep is probably 1min\n",
    "\n",
    "## Identification framework\n",
    "The following framework is proposed to identify The ETICS thermal conductivity\n",
    "- Measured data analysis and correction\n",
    "- Physical model description using Openmodelica\n",
    "- Sensitivity analysis to identify materials properties influence on the discrepancy\n",
    "- between model outputs and measured phenomenon\n",
    "- Etics thermal conductivity identification using optimization algorithm\n",
    "\n",
    "All these steps are addressed using **Modelitool** library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3768a5bb",
   "metadata": {},
   "source": [
    "# Measured data analysis and correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f9bac0",
   "metadata": {},
   "source": [
    "Measured data are loaded using <code>pandas</code> python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aeb02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\n",
    "    \"tuto_data.csv\",\n",
    "    sep=\",\",\n",
    "    index_col=0,\n",
    "    parse_dates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250c929",
   "metadata": {},
   "source": [
    "Plotting the raw temperatures gives precious information on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc901bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data[raw_data.columns[:3]].plot()\n",
    "raw_data['T_ext'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99064541",
   "metadata": {},
   "source": [
    "At first sight, the dataset looks ok. It doesn't mean it's clean. Missing values or incorrect variation are not always visible on a graphe.\n",
    "\n",
    "In order to be fed to the physical (and to get results as accurate as possible) data must be processed and corrected. The following steps are propposed.\n",
    "\n",
    "#### 1- Identify anomalies:\n",
    "- __upper__ and __lower__ values as boundaries. Measured values outside the interval are considered wrong\n",
    "- upper and lower \"__rates__\". Measured value increasing beyond or below a defined threshold are considered wrong\n",
    "\n",
    "These boundaries are set depending on the measured physical phenomenon.\n",
    "Of course power and temperature will be configured differently.\n",
    "\n",
    "#### 2- Missing data interpolation\n",
    "Physical model don't like missing values, thus for each sensor we provide a method\n",
    "to interpolate wrong data. Here we choose a linear interpolation between missing point.\n",
    " Errors at the beginning or at the end of the time series are filled with first or last correct value\n",
    "\n",
    "#### 3- Reducing dataset size\n",
    "Finally, a 1-minute acquisition timestep provides a heavy dataset.\n",
    "Moreover, a small timestep is not required to identify physical phenomenon.\n",
    "It is necessary to provide an aggregation method to _resample_ the dataset\n",
    "\n",
    "We use the class <code>MeasuredDats</code> from **Modelitool** to do so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c38cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelitool.measure import MeasuredDats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae6fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy is required here to provide resampling method\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = MeasuredDats(\n",
    "    data = raw_data,\n",
    "    data_type_dict = {\n",
    "        \"temperatures\": [\n",
    "            'T_Wall_Ins_1', 'T_Wall_Ins_2', 'T_Ins_Ins_1', 'T_Ins_Ins_2',\n",
    "            'T_Ins_Coat_1', 'T_Ins_Coat_2', 'T_int_1', 'T_int_2', 'T_ext', 'T_garde'\n",
    "        ],\n",
    "        \"illuminance\": [\"Lux_CW\"],\n",
    "        \"radiation\": [\"Sol_rad\"]\n",
    "    },\n",
    "    corr_dict = {\n",
    "        \"temperatures\": {\n",
    "            \"minmax\": {\n",
    "                \"upper\": 100,\n",
    "                \"lower\": -20\n",
    "            },\n",
    "            \"derivative\": {\n",
    "                \"upper_rate\": 2,\n",
    "                \"lower_rate\": 0,\n",
    "            },\n",
    "            \"fill_nan\": [\n",
    "                \"linear_interpolation\",\n",
    "                \"bfill\",\n",
    "                \"ffill\"\n",
    "            ],\n",
    "            \"resample\": np.mean,\n",
    "        },\n",
    "        \"illuminance\": {\n",
    "            \"minmax\": {\n",
    "                \"upper\": 1000,\n",
    "                \"lower\": 0,\n",
    "            },\n",
    "            \"derivative\": {\n",
    "                \"upper_rate\": 10E8, # Specifying high value is a way to discard correction\n",
    "                \"lower_rate\": -1, # Specifying negative value is a way to discard correction\n",
    "            },\n",
    "            \"fill_nan\": [\n",
    "                \"linear_interpolation\",\n",
    "                \"bfill\",\n",
    "                \"ffill\"\n",
    "            ],\n",
    "            \"resample\": np.mean,\n",
    "        },\n",
    "        \"radiation\": {\n",
    "            \"minmax\": {\n",
    "                \"upper\": 1000,\n",
    "                \"lower\": 0,\n",
    "            },\n",
    "            \"derivative\": {\n",
    "                \"upper_rate\": 10E8, # Specifying high value is a way to discard correction\n",
    "                \"lower_rate\": -1, # Specifying negative value is a way to discard correction\n",
    "            },\n",
    "            \"fill_nan\": [\n",
    "                \"linear_interpolation\",\n",
    "                \"bfill\",\n",
    "                \"ffill\"\n",
    "            ],\n",
    "            \"resample\": np.mean,\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea3932",
   "metadata": {},
   "source": [
    "The object <code>my_data</code> contains the original dataset and methode configuration for the correction.\n",
    "\n",
    "The <code>correction_journal</code> properties holds information on the data.\n",
    "\n",
    "Let's have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4db7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_data.correction_journal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814cb603",
   "metadata": {},
   "source": [
    "Before correction, the journal shows that ~2% of the data are missing for the temperature sensor and ~3% for external temperature, \"garde\" temperature and solar radiation. it correspond to data having a timstamp, but with missing value. In this specific case, this is not related to sensors errors. 2 distinct acquisition device were used to perform the measurement. The merging of the data from the two devices created troubles in timestamp \"alignement\". Also measurement stopped a bit earlier for the second device.  \n",
    "\n",
    "#### 1- Identify anomalies:\n",
    "Now let's apply the remove anomalies method to delete invalid data according to the specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386abd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.remove_anomalies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eed9525",
   "metadata": {},
   "source": [
    "Let's have a look at the <code>correction_journal</code>.\n",
    "Not all of it, as it stores every correction \"effect\". It will get big rapidly.\n",
    "First we want to see the new percentage of missing data after correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31dbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.correction_journal[\"remove_anomalies\"][\"missing_values\"][\"Percent_of_missing\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fd878",
   "metadata": {},
   "source": [
    "It looks like the applied corrections removed several data.\n",
    "For example, the sensors measuring the cell internal temperature have now up to __4.5%__ of missing data.\n",
    "\n",
    "Few corrections were applied to the outside temperature sensor.\n",
    "\n",
    "The journal of correction holds further information on the gaps of data.\n",
    "For example if we want to know more about the missing values of <code>T_int_1</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a01c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.correction_journal[\"remove_anomalies\"][\"gaps_stats\"][\"T_int_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b3f59",
   "metadata": {},
   "source": [
    "- There are 11233 gaps.\n",
    "- The size of 75% of these gaps do not exceed 1 timestep (~1min)\n",
    "- The biggest is 1h\n",
    "\n",
    "It is also possible to \"aggregate\" the gaps in to know when at least one of the data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724533ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.correction_journal[\"remove_anomalies\"][\"gaps_stats\"][\"combination\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c767b8",
   "metadata": {},
   "source": [
    "- There are 28066 gaps (~10% of the dataset).\n",
    "- The size of 75% of these gaps do not exceed 1 timestep (~1min)\n",
    "- The biggest gap is 1h\n",
    "\n",
    "There is not a lot of difference. It looks like the values are missing at the same timestamps.\n",
    "\n",
    "This is a good news, it means that there are a lot of periods with all data available\n",
    "\n",
    "We may want to access the new corrected data set to perform further investigations. It is available at <code>corrected_data</code> in <code>MeasuredDats</code> object.\n",
    "\n",
    "_Note that the original data set is left untouched in <code>data</code>_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a7b15",
   "metadata": {},
   "source": [
    "#### 2- Missing data interpolation\n",
    "Fill the missing data using specified interpolation and <code>fill_nan()</code> methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d41c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.fill_nan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c870f",
   "metadata": {},
   "source": [
    "Once again lets ahe a look to the <code>correction_journal</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca472de",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.correction_journal[\"fill_nan\"][\"missing_values\"][\"Percent_of_missing\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ccf064",
   "metadata": {},
   "source": [
    "Wow, perfect dataset !\n",
    "\n",
    "Be careful 0 data missing doesn't mean 0 problem.\n",
    " If you had a crappy dataset, it is still crappy.\n",
    " You just filled the gaps by copying values or drawing lines between (_what seems to be_) valid points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3effa3",
   "metadata": {},
   "source": [
    "#### 3- Reducing dataset size\n",
    "As we said earlier 1min timestep is too small.\n",
    "Regarding the physical phenomenon involved here, we could say that 5min is ok.\n",
    "\n",
    "So lets resample the dataset to this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262da474",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.resample(\"5T\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600f217",
   "metadata": {},
   "source": [
    "And that's it, we have fairly clean data to work with.\n",
    "\n",
    "We could export them directly into a **combiTimetable** file, but given the big gaps,\n",
    " and the measure campaign spanning over several months,\n",
    "  we probably want to identify an appropriate period for the identification.\n",
    "\n",
    "In our case, given the problem, we decide that this period shall be \n",
    "- short: not more than 7 days\n",
    "- with high temperature difference between <code>T_int</code> and <code>T_Ins_Coat</code>, that would maximise the heta transfers in the wall\n",
    "\n",
    "The following figure is designed to help us select the appropriate period. <code>Lux_CW</code> and <code>Sol_rad</code> are not shown for clarity purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e612fac",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Figure code\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for temp in my_data.corrected_data.columns[:-2]:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=my_data.corrected_data.index,\n",
    "        y=my_data.corrected_data[temp],\n",
    "        name = temp\n",
    "    ))\n",
    "\n",
    "# Edit the layout\n",
    "fig.update_layout(\n",
    "    title='Measured temperatures [°C]',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Temperature [°C]')\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dabd24d",
   "metadata": {},
   "source": [
    "We decide to select 2 consecutive days: 22/03 and 23/03. \n",
    "\n",
    "During the first day the coating temperature is rising up to 50 °C while cell\n",
    " temperature is controlled at ~26 °C and external temperature does not rise above 13 °C.\n",
    " It is characteristic of a highly insulated day, with heat transfers due to interior/exterior temperature drop .\n",
    "\n",
    "During the second day, coating temperature only reach ~21 °C (7 °C above external temperature).\n",
    " Which is characteristic of a fairly cloudy day. _Note that we could check solar radiation on another graph_\n",
    "\n",
    "**Regarding measure confidence:**\n",
    "- There is a 1 °C gap between the measurement of indoor air temperature.\n",
    "- The gap between temperatures measured at the interface of the two layer of insulation reaches 4 °C.\n",
    "\n",
    "This problem is not observed with the remaining sensors.\n",
    " This discrepancy is not negligible and shall be further investigated.\n",
    " However, in the scope of the tutorial, we will just take the mean of the sensor values.\n",
    "\n",
    "We use <code>combitabconvert.df_to_combitimetable()</code> to generate the boundary\n",
    " condition file that will be read by modelica model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c478cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelitool.combitabconvert import df_to_combitimetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas lines to combine sensors measures\n",
    "combined_measure = my_data.corrected_data[['T_ext', 'Sol_rad']].copy()\n",
    "combined_measure['T_Wall_Ins'] = my_data.corrected_data[\n",
    "    ['T_Wall_Ins_1', 'T_Wall_Ins_2']].mean(axis=1)\n",
    "combined_measure['T_Ins_Ins'] = my_data.corrected_data[\n",
    "    ['T_Ins_Ins_1', 'T_Ins_Ins_2']].mean(axis=1)\n",
    "combined_measure['T_Ins_Coat'] = my_data.corrected_data[\n",
    "    ['T_Ins_Coat_1', 'T_Ins_Coat_2']].mean(axis=1)\n",
    "combined_measure['T_int'] = my_data.corrected_data[\n",
    "    ['T_int_1', 'T_int_2']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_combitimetable(\n",
    "    df=combined_measure.loc[\"2018-03-22\":\"2018-03-23\"],\n",
    "    filename=\"boundary_temp.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9778e403",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It is now time to build the physical model using modelica !!!\n",
    "\n",
    "**_Note : Note that you will have to manually configure the file path in\n",
    "the <code>combiTimetable</code> of your modelica model_**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}