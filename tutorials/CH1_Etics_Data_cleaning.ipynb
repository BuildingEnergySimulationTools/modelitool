{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "398f247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553f8dc4",
   "metadata": {},
   "source": [
    "***Notebooks are written for Jupyter and might not display well in Gitlab***\n",
    "\n",
    "\n",
    "# Tutorial material property identification using modelitool "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85508d",
   "metadata": {},
   "source": [
    "The aim of this tutorial is to provide a complete workflow from measured data treatment to material physical properties identification using **Modelitool** and **OpenModelica**.\n",
    "\n",
    "### _The use case is an example and the validity of the physical model or of the scientific approach is not discussed here_\n",
    "\n",
    "## Use case presentation\n",
    "\n",
    "The objective of the study is to identify the thermal conductivity of the insulation material \"ETICS\"\n",
    "using an experimental setup.\n",
    "\n",
    "A \"real scale\" benchmark is used. The Nobatek **BEF** (Banc d'Essais Façade)\n",
    " provides experimental cells to test building façade solutions. The heat exchanges\n",
    " in a cell are limited on 5 of its faces. The 6th face is dedicated to the tested solution.\n",
    "  Internal temperature and hydrometry conditions can be controlled or monitored.\n",
    "External conditions are measured (temperatures and solar radiation).\n",
    "\n",
    "The experimental setup is presented in the following pictures:\n",
    "\n",
    "| Figure 1: picture of the benchmark | Figure 2: wall layers from the inside (right) to the outside (left) |\n",
    "| :---: | :---: |\n",
    "|<img src=\"images/etics_pict.png\"  height=\"300\"> | <img src=\"images/etics_sch.png\"  height=\"300\"> |\n",
    "\n",
    "The stars represent the sensors positions. For each position 2 sensors are used providing two measures.\n",
    "\n",
    "- Measure campaign spans from the 07/06/2017 to the 20/06/2017\n",
    "- Acquisition timestep is probably 1min\n",
    "\n",
    "## Identification framework\n",
    "The following framework is proposed to identify The ETICS thermal conductivity\n",
    "- Measured data analysis and correction\n",
    "- Physical model description using Openmodelica\n",
    "- Sensitivity analysis to identify materials properties influence on the discrepancy\n",
    "- between model outputs and measured phenomenon\n",
    "- Etics thermal conductivity identification using optimization algorithm\n",
    "\n",
    "All these steps are addressed using **Modelitool** library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3768a5bb",
   "metadata": {},
   "source": [
    "# Measured data analysis and correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f9bac0",
   "metadata": {},
   "source": [
    "Measured data are loaded using <code>pandas</code> python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aeb02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\n",
    "    Path(r\"ressources/tuto_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index_col=0,\n",
    "    parse_dates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250c929",
   "metadata": {},
   "source": [
    "Plotting the raw temperatures gives precious information on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc901bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data[raw_data.columns[:3]].plot()\n",
    "raw_data['T_ext'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99064541",
   "metadata": {},
   "source": [
    "At first sight, the dataset looks ok. It doesn't mean it's clean. Missing values or incorrect variation are not always visible on a graphe.\n",
    "\n",
    "In order to be fed to the physical (and to get results as accurate as possible) data must be processed and corrected. The following steps are propposed.\n",
    "\n",
    "#### 1- Identify anomalies:\n",
    "- __upper__ and __lower__ values as boundaries. Measured values outside the interval are considered wrong\n",
    "- upper and lower \"__rates__\". Measured value increasing beyond or below a defined threshold are considered wrong\n",
    "\n",
    "These boundaries are set depending on the measured physical phenomenon.\n",
    "Of course power and temperature will be configured differently.\n",
    "\n",
    "#### 2- Missing data interpolation\n",
    "Physical model don't like missing values, thus for each sensor we provide a method\n",
    "to interpolate wrong data. Here we choose a linear interpolation between missing point.\n",
    " Errors at the beginning or at the end of the time series are filled with first or last correct value\n",
    "\n",
    "#### 3- Reducing dataset size\n",
    "Finally, a 1-minute acquisition timestep provides a heavy dataset.\n",
    "Moreover, a small timestep is not required to identify physical phenomenon.\n",
    "It is necessary to provide an aggregation method to _resample_ the dataset\n",
    "\n",
    "We use the class <code>MeasuredDats</code> from **Modelitool** to do so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c38cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelitool.measure import MeasuredDats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = MeasuredDats(\n",
    "    data = raw_data,\n",
    "    data_type_dict = {\n",
    "        \"temperatures\": [\n",
    "            'T_Wall_Ins_1', 'T_Wall_Ins_2', 'T_Ins_Ins_1', 'T_Ins_Ins_2',\n",
    "            'T_Ins_Coat_1', 'T_Ins_Coat_2', 'T_int_1', 'T_int_2', 'T_ext', 'T_garde'\n",
    "        ],\n",
    "        \"illuminance\": [\"Lux_CW\"],\n",
    "        \"radiation\": [\"Sol_rad\"]\n",
    "    },\n",
    "    corr_dict = {\n",
    "        \"temperatures\": {\n",
    "            \"minmax\": {\n",
    "                \"upper\": 100,\n",
    "                \"lower\": -20\n",
    "            },\n",
    "            \"derivative\": {\n",
    "                \"upper_rate\": 2,\n",
    "                \"lower_rate\": 0,\n",
    "            },\n",
    "            \"fill_nan\": [\n",
    "                \"linear_interpolation\",\n",
    "                \"bfill\",\n",
    "                \"ffill\"\n",
    "            ],\n",
    "            \"resample\": 'mean',\n",
    "        },\n",
    "        \"illuminance\": {\n",
    "            \"minmax\": {\n",
    "                \"upper\": 1000,\n",
    "                \"lower\": 0,\n",
    "            },\n",
    "            \"derivative\": {\n",
    "                \"upper_rate\": 10E8, # Specifying high value is a way to discard correction\n",
    "                \"lower_rate\": -1, # Specifying negative value is a way to discard correction\n",
    "            },\n",
    "            \"fill_nan\": [\n",
    "                \"linear_interpolation\",\n",
    "                \"bfill\",\n",
    "                \"ffill\"\n",
    "            ],\n",
    "            \"resample\": 'mean',\n",
    "        },\n",
    "        \"radiation\": {\n",
    "            \"minmax\": {\n",
    "                \"upper\": 1000,\n",
    "                \"lower\": 0,\n",
    "            },\n",
    "            \"derivative\": {\n",
    "                \"upper_rate\": 10E8, # Specifying high value is a way to discard correction\n",
    "                \"lower_rate\": -1, # Specifying negative value is a way to discard correction\n",
    "            },\n",
    "            \"fill_nan\": [\n",
    "                \"linear_interpolation\",\n",
    "                \"bfill\",\n",
    "                \"ffill\"\n",
    "            ],\n",
    "            \"resample\": 'mean',\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The <code>plot</code> method can be used to plot the data.\n",
    "\n",
    "Provide a <code>list</code> to the argument <code>cols</code> to specify the entry you want to plot.\n",
    "\n",
    "A new y axis will be created for each data type."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_data.plot(\n",
    "    cols=['T_Wall_Ins_1', 'Sol_rad', 'Lux_CW'],\n",
    "    begin='2018-04-15',\n",
    "    end='2018-04-18',\n",
    "    title='Plot uncorrected data',\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotted data are the <code>corrected_data</code>. <code>plot_raw=True</code> to display raw data. This is useful to assess the impact of the correction and of the resampling methods\n",
    "\n",
    "For now no corrections have been applied, so <code>corrected_data</code> is equal to <code>data</code>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "efea3932",
   "metadata": {},
   "source": [
    "\n",
    "The object <code>my_data</code> contains the original dataset and methode configuration for the correction.\n",
    "\n",
    "The <code>correction_journal</code> properties holds information on the data.\n",
    "\n",
    "Let's have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4db7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_data.correction_journal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814cb603",
   "metadata": {},
   "source": [
    "Before correction, the journal shows that ~2% of the data are missing for the temperature sensor and ~3% for external temperature, \"garde\" temperature and solar radiation. it correspond to data having a timstamp, but with missing value. In this specific case, this is not related to sensors errors. 2 distinct acquisition device were used to perform the measurement. The merging of the data from the two devices created troubles in timestamp \"alignement\". Also measurement stopped a bit earlier for the second device.  \n",
    "\n",
    "#### 1- Identify anomalies:\n",
    "Now let's apply the remove anomalies method to delete invalid data according to the specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386abd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.remove_anomalies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eed9525",
   "metadata": {},
   "source": [
    "Let's have a look at the <code>correction_journal</code>.\n",
    "Not all of it, as it stores every correction \"effect\". It will get big rapidly.\n",
    "First we want to see the new percentage of missing data after correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31dbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.correction_journal[\"remove_anomalies\"][\"missing_values\"][\"Percent_of_missing\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fd878",
   "metadata": {},
   "source": [
    "It looks like the applied corrections removed several data.\n",
    "For example, the sensors measuring the cell internal temperature have now up to __4.5%__ of missing data.\n",
    "\n",
    "Few corrections were applied to the outside temperature sensor.\n",
    "\n",
    "The journal of correction holds further information on the gaps of data.\n",
    "For example if we want to know more about the missing values of <code>T_int_1</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a01c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.correction_journal[\"remove_anomalies\"][\"gaps_stats\"][\"T_int_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b3f59",
   "metadata": {},
   "source": [
    "- There are 11233 gaps.\n",
    "- The size of 75% of these gaps do not exceed 1 timestep (~1min)\n",
    "- The biggest is 1h\n",
    "\n",
    "It is also possible to \"aggregate\" the gaps in to know when at least one of the data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724533ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.correction_journal[\"remove_anomalies\"][\"gaps_stats\"][\"combination\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c767b8",
   "metadata": {},
   "source": [
    "- There are 28066 gaps (~10% of the dataset).\n",
    "- The size of 75% of these gaps do not exceed 1 timestep (~1min)\n",
    "- The biggest gap is 1h\n",
    "\n",
    "There is not a lot of difference. It looks like the values are missing at the same timestamps.\n",
    "\n",
    "This is a good news, it means that there are a lot of periods with all data available"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The plotting method <code>plot_gaps<code> can be used to visualize where the gap happened.\n",
    "\n",
    "This dataset holds a lot of values, sol we just plot the entry <code>'T_int_1'</code> that is supposed to have the more gaps\n",
    "\n",
    "We are interested in gaps lasting more than 15 minutes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "my_data.plot_gaps(cols=['T_int_1'], gaps_timestep=dt.timedelta(minutes=15))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There seem to be only 1 gap greater than 15minutes, and it is a bit hard to see. You can zoom in to the 2018-03-25, you will notice a gap between ~02:00 and ~3:00.\n",
    "Yhis is the gap we saw in the correction journal."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We may want to access the new corrected data set to perform further investigations. It is available at <code>corrected_data</code> in <code>MeasuredDats</code> object.\n",
    "\n",
    "_Note that the original data set is left untouched in <code>data</code>_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "4e5a7b15",
   "metadata": {},
   "source": [
    "#### 2- Missing data interpolation\n",
    "Fill the missing data using specified interpolation and <code>fill_nan()</code> methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d41c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.fill_nan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c870f",
   "metadata": {},
   "source": [
    "Once again lets ahe a look to the <code>correction_journal</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca472de",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.correction_journal[\"fill_nan\"][\"missing_values\"][\"Percent_of_missing\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ccf064",
   "metadata": {},
   "source": [
    "Wow, perfect dataset !\n",
    "\n",
    "Be careful 0 data missing doesn't mean 0 problem.\n",
    " If you had a crappy dataset, it is still crappy.\n",
    " You just filled the gaps by copying values or drawing lines between (_what seems to be_) valid points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3effa3",
   "metadata": {},
   "source": [
    "#### 3- Reducing dataset size\n",
    "As we said earlier 1min timestep is too small.\n",
    "Regarding the physical phenomenon involved here, we could say that 5min is ok.\n",
    "\n",
    "So lets resample the dataset to this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262da474",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.resample(\"5T\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's have a look at our corrected data versus the raw data.\n",
    "\n",
    "We select a period around the gap we identified (from the 2018-03-24 to the 2018-03-26)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_data.plot(\n",
    "    title=\"Raw data versus corrected data\",\n",
    "    cols=['T_int_1'],\n",
    "    begin='2018-03-25 00:00:00',\n",
    "    end='2018-03-25 05:00:00',\n",
    "    plot_raw=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On the above graph you can see the effects of mean resampling, that diminishes the number of points and smooths out the data.\n",
    "\n",
    "The gap have been filled using linear interpolation at the required timestep.\n",
    "\n",
    "It is important to compare your data before and after applying the correction methods. For example, resampling with a large timestep can lead to a loss of information"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "3600f217",
   "metadata": {},
   "source": [
    "And that's it, we have fairly clean data to work with.\n",
    "\n",
    "We could export them directly into a **combiTimetable** file, but given the big gaps,\n",
    " and the measure campaign spanning over several months,\n",
    "  we probably want to identify an appropriate period for the identification.\n",
    "\n",
    "In our case, given the problem, we decide that this period shall be \n",
    "- short: not more than 7 days\n",
    "- with high temperature difference between <code>T_int</code> and <code>T_Ins_Coat</code>, that would maximise the heta transfers in the wall\n",
    "\n",
    "The following figure is designed to help us select the appropriate period. <code>Lux_CW</code> and <code>Sol_rad</code> are not shown for clarity purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e612fac",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Figure code\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for temp in my_data.corrected_data.columns[:-2]:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=my_data.corrected_data.index,\n",
    "        y=my_data.corrected_data[temp],\n",
    "        name = temp\n",
    "    ))\n",
    "\n",
    "# Edit the layout\n",
    "fig.update_layout(\n",
    "    title='Measured temperatures [°C]',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Temperature [°C]')\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dabd24d",
   "metadata": {},
   "source": [
    "We decide to select 2 consecutive days for the identification (22/03 and 23/03)\n",
    " and 2 other dys for the validation (26/03 and 28/03)\n",
    "\n",
    "During the first day the coating temperature is rising up to 50 °C while cell\n",
    " temperature is controlled at ~26 °C and external temperature does not rise above 13 °C.\n",
    " It is characteristic of a highly insulated day, with heat transfers due to interior/exterior temperature drop .\n",
    "\n",
    "During the second day, coating temperature only reach ~21 °C (7 °C above external temperature).\n",
    " Which is characteristic of a fairly cloudy day. _Note that we could check solar radiation on another graph_\n",
    "\n",
    "**Regarding measure confidence:**\n",
    "- There is a 1 °C gap between the measurement of indoor air temperature.\n",
    "- The gap between temperatures measured at the interface of the two layer of insulation reaches 4 °C.\n",
    "\n",
    "This problem is not observed with the remaining sensors.\n",
    " This discrepancy is not negligible and shall be further investigated.\n",
    " However, in the scope of the tutorial, we will just take the mean of the sensor values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas lines to combine sensors measures\n",
    "combined_measure = my_data.corrected_data[['T_ext', 'Sol_rad']].copy()\n",
    "combined_measure['T_Wall_Ins'] = my_data.corrected_data[\n",
    "    ['T_Wall_Ins_1', 'T_Wall_Ins_2']].mean(axis=1)\n",
    "combined_measure['T_Ins_Ins'] = my_data.corrected_data[\n",
    "    ['T_Ins_Ins_1', 'T_Ins_Ins_2']].mean(axis=1)\n",
    "combined_measure['T_Ins_Coat'] = my_data.corrected_data[\n",
    "    ['T_Ins_Coat_1', 'T_Ins_Coat_2']].mean(axis=1)\n",
    "combined_measure['T_int'] = my_data.corrected_data[\n",
    "    ['T_int_1', 'T_int_2']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For future use in next chapter, we save the corrected measure during\n",
    "the period of interest, so we can load it in the next chapters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_measure.loc[\"2018-03-22\":\"2018-03-28\"].to_csv(\n",
    "    \"ressources/study_df.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part of the measurements will be used as boundary conditions for the simulation.\n",
    "__Modelitool__ allows you to pass <code>DataFrame</code> to the <code>Simulator</code> that handles OpenModelica models.\n",
    "This way you don't have to worry about generating boundary text file.\n",
    "\n",
    "\n",
    "But if you want to generate your own boundary file, (to simulate using OpemModelica Editor for example),\n",
    "you can use <code>combitabconvert.df_to_combitimetable()</code> to generate the boundary\n",
    " condition file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modelitool.combitabconvert import df_to_combitimetable\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_combitimetable(\n",
    "    df=combined_measure.loc[\"2018-03-22\":\"2018-03-23\"],\n",
    "    filename=\"ressources/boundary_temp.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9778e403",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It is now time to build the physical model using modelica !!!\n",
    "\n",
    "**_Note : Note that you will have to manually configure the file path in\n",
    "the <code>combiTimetable</code> of your modelica model_**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}