{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "TUTORIAL_DIR = Path(os.getcwd()).as_posix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Notebooks are written for Jupyter and might not display well in Gitlab***\n",
    "\n",
    "# Physical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we propose a resistance/capacity approach.\n",
    " Based on electrical circuit analogy, each layer of the wall is modeled by two resistance and a capacity:\n",
    "\n",
    "<img src=\"images/Wall_model.png\"  height=\"300\">\n",
    "\n",
    "The following is a brief description of the thermal model, as it is not the scope of this document. See the <code>*mo</code> for full informations.\n",
    "\n",
    "- Each wall layer is modeled by 2 thermal resistances and a capacity.\n",
    "    - Resistances : $ R_1 = R_2 = \\frac{ep_{layer}}{lambda_{layer} \\times 2} $\n",
    "    - Capacity : $ C = ep_{layer} \\times rho_{layer} \\times cap_{layer} $\n",
    "\n",
    "\n",
    "- Inside and outside convection/conduction transfers are model as a constant value thermal resistance.\n",
    "\n",
    "\n",
    "- Infrared transfers are considered :\n",
    "    - With the sky, with $ T_{sky} = 0.0552T_{ext}^{1.5} $\n",
    "    - With the surrounding considered to be at $ T_{ext} $\n",
    "\n",
    "\n",
    "- Short wave solar radiation heat flux is computed $Sw_{gain} = Pyr \\times \\alpha_{coat} $ with $Pyr$ the measured solar radiation onthe wall (W/mÂ²) and  $\\alpha_{coat}$ the coating solar absorbtion coefficient.\n",
    "\n",
    "\n",
    "- Temperatures $ T_{ext}$ and $T_{int} $ are boundary conditions\n",
    "\n",
    "\n",
    "Initial conditions for the layers temperatures are taken from the measured data.\n",
    " It is assumed to be the mean temperature measured by the sensors on each face of a layer.\n",
    " In python and using modelica \"object name\", it can be written :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "init_dict = {\n",
    "    \"Twall_init\": 24.81 + 273.15,\n",
    "    \"Tins1_init\": 19.70 + 273.15,\n",
    "    \"Tins2_init\": 10.56 + 273.15,\n",
    "    \"Tcoat_init\": 6.4 + 273.15,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the simulation running options. As the initial condition, it is written\n",
    "as a python dictionary.\n",
    "\n",
    "In Modelica, <code>startTime</code> and <code>stopTime</code> correspond to the number\n",
    "of seconds since the beginning of the year. The values can be found in the file created\n",
    "earlier using <code>df_to_combitimetable</code>\n",
    "\n",
    "<code>stepSize</code> is the simulation timestep size. In this case it's 5min or\n",
    "300sec.\n",
    "\n",
    "<code>tolerance</code> and <code>solver</code> are related to solver configuration\n",
    "do not change if you don't need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "simulation_opt = {\n",
    "        \"startTime\": 6912000,\n",
    "        \"stopTime\": 7084500,\n",
    "        \"stepSize\": 300,\n",
    "        \"tolerance\": 1e-06,\n",
    "        \"solver\": \"dassl\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define a modelitool <code>Simulator</code>. This object is designed\n",
    "to handle modelica simulation and output post treatment. It will be used\n",
    "in objects that automate simulation such as an <code>Identificator</code>\n",
    "or a <code>SAnalysis</code> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from modelitool.simulate import Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Values in output list correspond to sensors name and value \"T\"\n",
    "simu = Simulator(\n",
    "    model_path=Path(TUTORIAL_DIR) / \"ressources/etics_v0.mo\",\n",
    "    simulation_options=simulation_opt,\n",
    "    init_parameters=init_dict,\n",
    "    output_list=[\"T_coat_ins.T\",\n",
    "                 \"T_ins_ins.T\",\n",
    "                 \"Tw_out.T\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From here, it is very simple to run a simulation using <code>simulate()</code>\n",
    "method, and to get the results required in <code>output_list</code> using\n",
    "<code>get_results()</code> method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "simu.simulate()\n",
    "initial_results = simu.get_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If we want to compare these results to the measures, we have to load the\n",
    "boundary file.\n",
    "\n",
    "*Note: since Modelica uses seconds, time axis in the rest of the document it will\n",
    " be in seconds. A conversion function might be integrated in next versions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Pandas lines to load boundary file\n",
    "reference_df = pd.read_csv(\n",
    "    Path(TUTORIAL_DIR) / \"ressources/boundary_temp.txt\",\n",
    "    skiprows=3,\n",
    "    sep='\\t',\n",
    "    index_col=0,\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "reference_df.columns = [\"T_ext\", \"Sol_rad\", \"T_Wall_Ins\", \"T_Ins_Ins\",\n",
    "                        \"T_Ins_Coat\", \"T_int\"]\n",
    "\n",
    "temperature_columns = [\"T_ext\", \"T_Wall_Ins\", \"T_Ins_Ins\",\n",
    "                        \"T_Ins_Coat\", \"T_int\"]\n",
    "\n",
    "reference_df[temperature_columns] = reference_df[temperature_columns] + 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plotly lines\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=initial_results.index,\n",
    "    y=initial_results[\"T_ins_ins.T\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='brown',\n",
    "    name=\"Model_results\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=reference_df.index,\n",
    "    y=reference_df.T_Ins_Ins,\n",
    "    fill='tonexty', # fill area between trace0 and trace1\n",
    "    mode='lines',\n",
    "    line_color='orange',\n",
    "    name=\"Reference_measure\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Model VS Reality : temperature between two layer of insulation',\n",
    "    xaxis_title='Time [sec since 01/01]',\n",
    "    yaxis_title='Temperature [K]')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Considering the above graphic, we could say that the model results are pretty bad.\n",
    "- The difference between predicted and measured temperature reaches ~10K\n",
    "- There seem to be a small \"shift\" between model and reality.\n",
    "Reference temperature peaks are happening earlier than model peaks.\n",
    "\n",
    "There can be a lot of causes to this discrepancy. From physical phenomenon approximation\n",
    "to material physical properties values.\n",
    "\n",
    "*A good Idea would be to plot the other outputs variables or to perform a heat\n",
    "balance analysis. But remember that this is a tutorial to use modelitool :).*\n",
    "\n",
    "*For now we will just go on, and perform a sensitivity analysis*\n",
    "\n",
    "# Sensitivity analisys\n",
    "\n",
    "This project aims at characterizing the insulation material thermal conductivity.\n",
    "To do so, we want to find the value $ \\lambda_{etics} $ that would minimise the discrepancy between\n",
    "predicted temperature between 2 layers of insulation material and the sensors measures.\n",
    "\n",
    "However, it is very important to know how $ \\lambda_{etics} $ is important\n",
    "to describe the error. Other assumptions, such as material thermal properties may\n",
    "have a strong influence on the model prediction.\n",
    "\n",
    "Therefore, we use the sensitivity analysis to \"rank\" the parameter by order of influence\n",
    "on the error between measured temperature and model prediction.\n",
    "\n",
    "The chosen error function is the Mean Square Error (RMSE):\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{1-N}\\sum \\limits_{i=1}^{N} (y_i - \\hat y_i)^2\n",
    "$$\n",
    "\n",
    "The chosen parameters for the sensitivity analysis are listed below:\n",
    "- Concrete thermal capacity <code>capa_concrete</code> with an uncertainty of 20%\n",
    "- Concrete density <code>rho_concrete</code> with an uncertainty of 20%\n",
    "- All layer thermal conductivity with an uncertainty af 20%\n",
    "- The coating shortwave solar absorption coefficient <code>Alpha_clo</code>\n",
    "with an uncertainty of 20%\n",
    "- The inside and outside conductive/convective equivalent thermal resistance\n",
    "with an uncertainty of 20%\n",
    "\n",
    "In modelitool, these uncertainties must be described using a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modelitool_problem = {\n",
    "    \"capa_concrete\": [1000-0.2*1000, 1000+0.2*1000],\n",
    "    \"rho_concrete\": [875-0.2*875, 875+0.2*875],\n",
    "    \"lambda_concrete\": [1-0.2*1, 1+0.2*1],\n",
    "    \"lambda_coating\": [1-0.2*1, 1+0.2*1],\n",
    "    \"Lambda_ins.k\": [0.04-0.2*0.04, 0.04+0.2*0.04],\n",
    "    \"Alpha_clo.k\": [0.5-0.2*0.5, 0.5+0.2*0.5],\n",
    "    \"R_conv_ext.k\": [0.04-0.2*0.04, 0.04+0.2*0.04],\n",
    "    \"R_conv_int.k\": [0.13-0.2*0.13, 0.13+0.2*0.13],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now use a <code>SAnalysis</code> to set-up the study. We have to pass\n",
    "the <code>Simulator</code> previously describe, along with the corresponding\n",
    " problem description. A Sensitivity Analysis is also required. In this case we choose Sobol\n",
    ", as there is few uncertain parameter.\n",
    "\n",
    "*Note: for now only <code>Sobol</code>, <code>Sobol</code>, <code>FAST</code>,\n",
    "and <code>Morris</code> methods are implemented.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from modelitool.sensitivity import SAnalysis\n",
    "\n",
    "sa_study = SAnalysis(\n",
    "    simulator=simu,\n",
    "    sensitivity_method=\"Sobol\",\n",
    "    parameters_config=modelitool_problem\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We draw a sample of parameters to simulate. Each method has its sampling method.\n",
    "Please see SALib documentation for further explanation (https://salib.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Additional arguments can be passed. if arguments is not used it\n",
    "# Uses default SALib configuration\n",
    "sa_study.draw_sample(n=100, arguments={\"calc_second_order\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The sample is available as a 2d array <code>sa_study.sample</code>. Lines are simulations\n",
    "to run and columns are parameters values.\n",
    "\n",
    "Let's run the simulations.\n",
    "\n",
    "**CAREFUL depending on your computer, it can take a long time (up to 30')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sa_study.run_simulations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sa_study.analyze(\n",
    "    aggregation_method=mean_squared_error,\n",
    "    indicator=\"T_ins_ins.T\",\n",
    "    reference=reference_df[\"T_Ins_Ins\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now have a look at the sensitivity analysis results.\n",
    "They are stored in <code>sensitivity_results</code>. It holds the output formatted\n",
    "by <code>SALib</code>. It is possible to get it as a <code>DataFrame</code>\n",
    "using <code>to_df()</code> (see the doc).\n",
    "\n",
    "First, let's sum the indices of Total order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sum_st = sa_study.sensitivity_results.to_df()[0].sum().loc[\"ST\"]\n",
    "mean_conf = sa_study.sensitivity_results.to_df()[0].mean().loc[\"ST_conf\"]\n",
    "\n",
    "print(\n",
    "    f\"The sum of Sobol Total or index is {sum_st} \\n\"\n",
    "    f\"The mean confidence interval is {mean_conf}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The sum of all the indices is very close to 1. Also, the mean confidence interval\n",
    "seems to be very low. Results of the sensitivity analysis appear to be robust.\n",
    "\n",
    "We can now plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sa_study.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Fortunately $\\lambda_{etics}$ seems to be the most influential parameter on the error between\n",
    "model outputs and sensor measure\n",
    "- Two other parameters have a strong influence on the error :\n",
    "    - the coating coefficient of absorption (solar radiation) $\\alpha_{coat}$\n",
    "    - the outside conduction/convection resistance\n",
    "- Looking at the interval of confidence, this ranking is reliable\n",
    "\n",
    "To understand the possible effects of interactions between parameter. We can\n",
    "have a look at the indices of order 1 an 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sum_s1 = sa_study.sensitivity_results.to_df()[1].sum().loc[\"S1\"]\n",
    "mean_conf1 = sa_study.sensitivity_results.to_df()[1].mean().loc[\"S1_conf\"]\n",
    "sum_s2 = sa_study.sensitivity_results.to_df()[2].sum().loc[\"S2\"]\n",
    "mean_conf2 = sa_study.sensitivity_results.to_df()[2].mean().loc[\"S2_conf\"]\n",
    "\n",
    "print(\n",
    "    f\"The sum of S1 index is {sum_s1} \\n\"\n",
    "    f\"The sum of S2 index is {sum_s2} \\n\"\n",
    "    f\"The S1 mean confidence interval is {mean_conf1}\\n\"\n",
    "    f\"The S2 mean confidence interval is {mean_conf2}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "These results are not very good (remember $ S_1 + S_2 + ... + S_n = 1 $)\n",
    "\n",
    "But it means that parameters are influential at the 1st order. The interaction effect\n",
    "between the parameters is negligible.\n",
    "\n",
    "# Conclusion on sensitivity analysis\n",
    "\n",
    "The sensitivity analysis allows us to rank the influence of uncertain parameter\n",
    "on an indicator. In this case we choose the $MSE$ between model output\n",
    "and measurement.\n",
    "\n",
    "Fortunately it shows that the most influential parameters was the insulation thermal\n",
    "conductivity. But we can't discard the coefficient of absorption of solar radiation\n",
    "that accounts for 30% of the variance of the error. Also, the thermal resistance that models\n",
    "the conductive/convective heat transfer is not negligible (~8% of the variance).\n",
    "\n",
    "In the following chapter, we will see how to use modelitool to identify the\n",
    "optimal values for these parameters in order to fit the measurement.\n",
    "\n",
    "We will also assess the reliability of the obtained values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}